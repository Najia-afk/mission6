{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©paration du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalAveragePooling1D, Flatten, Dense, Dropout \n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# os.environ[\"TF_KERAS\"]='1'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n",
      "1050\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7c189375-5e1e-412f-8425-cd311aa33549",
       "rows": [
        [
         "0",
         "./dataset/Flipkart/Images/aa68675f50a0551b8dadb954017a50a1.jpg",
         "no_name ",
         "0"
        ],
        [
         "1",
         "./dataset/Flipkart/Images/037c2402fee39fbc80433935711d1383.jpg",
         "no_name ",
         "0"
        ],
        [
         "2",
         "./dataset/Flipkart/Images/42643c1c9403f67921a18654bcf45ead.jpg",
         "no_name ",
         "0"
        ],
        [
         "3",
         "./dataset/Flipkart/Images/53f4bc7d7321f5c41de6b86e41f13e80.jpg",
         "no_name ",
         "0"
        ],
        [
         "4",
         "./dataset/Flipkart/Images/b144a363c107c7bdd91f32d6e28ba6f2.jpg",
         "no_name ",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/Flipkart/Images/aa68675f50a0551b8dad...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/Flipkart/Images/037c2402fee39fbc8043...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/Flipkart/Images/42643c1c9403f67921a1...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/Flipkart/Images/53f4bc7d7321f5c41de6...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/Flipkart/Images/b144a363c107c7bdd91f...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path label_name  label\n",
       "0  ./dataset/Flipkart/Images/aa68675f50a0551b8dad...   no_name       0\n",
       "1  ./dataset/Flipkart/Images/037c2402fee39fbc8043...   no_name       0\n",
       "2  ./dataset/Flipkart/Images/42643c1c9403f67921a1...   no_name       0\n",
       "3  ./dataset/Flipkart/Images/53f4bc7d7321f5c41de6...   no_name       0\n",
       "4  ./dataset/Flipkart/Images/b144a363c107c7bdd91f...   no_name       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "path = \"./dataset/Flipkart/Images/\"\n",
    "path_test = \"./dataset/Flipkart/Images/\"\n",
    "\n",
    "\n",
    "list_labels = [\"cloudy\", \"rain\", \"shine\", \"sunrise\"]\n",
    "label_no_name = \"no_name \"\n",
    "\n",
    "def photo_class(photo) :\n",
    "    for label in list_labels :\n",
    "        if label in photo[24:] : \n",
    "            return label\n",
    "    return label_no_name\n",
    "    \n",
    "data_path = glob(path+'*.jp*')\n",
    "data_test_path = glob(path_test+'*.jp*')\n",
    "\n",
    "def data_fct(path) :\n",
    "    list_photos = [file for file in path]\n",
    "    print(len(list_photos))\n",
    "    data = pd.DataFrame()\n",
    "    data[\"image_path\"] = list_photos\n",
    "    data[\"label_name\"] = data[\"image_path\"].apply(lambda x : photo_class(x))\n",
    "    return data\n",
    "\n",
    "data = data_fct(data_path)\n",
    "data_test = data_fct(data_test_path)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data[\"label_name\"])\n",
    "data[\"label\"] = le.transform(data[\"label_name\"])\n",
    "data_test[\"label\"] = le.transform(data_test[\"label_name\"])\n",
    "# data.head(5)\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "image_path",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label_name",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b356cf51-3731-4d92-93ea-838e1215a751",
       "rows": [],
       "shape": {
        "columns": 2,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image_path, label_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudy\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m     16\u001b[39m     plt.subplot(\u001b[32m130\u001b[39m + \u001b[32m1\u001b[39m + i)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     filename = \u001b[43mlist_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     18\u001b[39m     image = imread(filename)\n\u001b[32m     19\u001b[39m     plt.imshow(image)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "def list_fct(name) :\n",
    "    list_image_name = [data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==name]\n",
    "    return list_image_name\n",
    "\n",
    "list_cloudy=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"cloudy\"]\n",
    "list_rain=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"rain\"]\n",
    "list_shine=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"shine\"]\n",
    "list_sunrise=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"sunrise\"]\n",
    "\n",
    "for name in list_labels :\n",
    "    print(name)\n",
    "    # print(\"-------\")\n",
    "    for i in range(3):\n",
    "        plt.subplot(130 + 1 + i)\n",
    "        filename = list_fct(name)[i+10]\n",
    "        image = imread(filename)\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 : √©tude de faisabilit√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation du mod√®le pr√©-entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG16()\n",
    "model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation des features des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T13:11:24.767685Z",
     "start_time": "2020-12-31T13:09:49.843465Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_features = []\n",
    "i=0 \n",
    "for image_file in data[\"image_path\"] :\n",
    "    if i%100 == 0 : print(i)\n",
    "    i +=1\n",
    "    image = load_img(image_file, target_size=(224, 224))\n",
    "    image = img_to_array(image) \n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    images_features.append(model.predict(image, verbose=0)[0]) # predict from pretrained model\n",
    "\n",
    "images_features = np.asarray(images_features)\n",
    "images_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©duction dimension et analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©duction de dimension PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition\n",
    "\n",
    "print(images_features.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "feat_pca= pca.fit_transform(images_features)\n",
    "print(feat_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©duction de dimension T-SNE et affichage des images selon vraies classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition\n",
    "import time\n",
    "\n",
    "temps1 = time.time()\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000, init='random', random_state=6)\n",
    "X_tsne = tsne.fit_transform(feat_pca)\n",
    "\n",
    "duration1=time.time()-temps1\n",
    "print(\"temps de T-SNE : \", \"%15.2f\" % duration1, \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = pd.DataFrame(X_tsne, columns=['tsne1', 'tsne2'])\n",
    "df_tsne[\"class\"] = data[\"label_name\"]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"class\",\n",
    "    palette=sns.color_palette('tab10', n_colors=4), s=50, alpha=0.6,\n",
    "    data=df_tsne,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE selon les vraies classes', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'analyse graphique montre visuellement qu'il est r√©alisable de s√©parer automatiquement les images selon leurs vraies classes\n",
    "* Ceci suffit √† d√©montrer la faisabilit√© de r√©aliser ult√©rieurement une classification supervis√©e pour d√©terminer automatiquement les classes des images\n",
    "* Cette √©tape 1 est tr√®s rapide √† mettre en oeuvre. Une conclusion n√©gative sur la faisabilit√© aurait √©viter de r√©aliser des traitements beaucoup plus lourd de classification supervis√©e\n",
    "* Cette d√©marche en 2 √©tapes (1. Faisabilit√©, 2. Classification supervis√©e si √©tape 1 OK) s'inscrit dans une d√©marche agile de tout projet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©ation de clusters √† partir du T-SNE et affichage des images selon clusters\n",
    "* Attention : ici, il ne s'agit pas de faire une classification non supervis√©e, mais simplement, par une mesure de l'ARI, de conforter l'analyse graphique pr√©c√©dente qui d√©montre la faisabilit√© de r√©aliser ult√©rieurement une classification supervis√©e. Cette mesure de l'ARI n√©cessite de cr√©er des clusters th√©oriques via KMeans\n",
    "* Il s'agit donc de r√©aliser une mesure de ce que nous voyons graphiquement, donc √† partir des donn√©es en sortie du t-sne\n",
    "* Pour r√©aliser une classification non supervis√©e, il aurait fallu repartir des donn√©es avant t-sne\n",
    "* Dans la d√©marche en 2 √©tapes, il n'est pas utile de r√©aliser une classification non supervis√©e, une classification supervis√©e est bien plus performante. M√™me le calcul de l'ARI n'est pas indispensable, nous pourrions passer directement du graphique t-sne pr√©c√©dent √† l'√©tape 2 de classification supervis√©e\n",
    "* Il n'est donc pas utile de passer du temps √† optimiser l'ARI, un ordre de grandeur suffit pour conforter le 1er graphique t-sne. D'ailleurs la meilleure solution de feature engineering ne g√©n√®re pas toujours le meilleur ARI. L'analyse graphique t-sne est bien plus riche d'enseignement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, metrics\n",
    "\n",
    "cls = cluster.KMeans(n_clusters=4, n_init=100)\n",
    "cls.fit(X_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tsne[\"cluster\"] = cls.labels_\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette('tab10', n_colors=4), s=50, alpha=0.6,\n",
    "    data=df_tsne,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = data[\"label\"]\n",
    "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse d'image \"shine\" affect√©es au cluster 3 \"cloudy\"\n",
    "\n",
    "list_shine_0 = [i for i in range(len(data[\"image_path\"])) \\\n",
    "                if (data.iloc[i]['label_name']=='shine') and (df_tsne.iloc[i]['cluster']==3)]\n",
    "list_shine_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage image \"shine\" consid√©r√©e comme \"cloudy\"\n",
    "id = 220\n",
    "print(df_tsne.iloc[id])\n",
    "fig = plt.figure(figsize = (8, 5))\n",
    "# plt.subplot(130 + 1 + i)\n",
    "filename = data[\"image_path\"][id]\n",
    "image = imread(filename)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyse : le mod√®le pr√©-entra√Æn√© confond \"cloud\" avec de la neige ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse par classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(labels, cls.labels_)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_transform(y_true,y_pred) :\n",
    "    conf_mat = metrics.confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    corresp = np.argmax(conf_mat, axis=0)\n",
    "    print (\"Correspondance des clusters : \", corresp)\n",
    "    # y_pred_transform = np.apply_along_axis(correspond_fct, 1, y_pred)\n",
    "    labels = pd.Series(y_true, name=\"y_true\").to_frame()\n",
    "    labels['y_pred'] = y_pred\n",
    "    labels['y_pred_transform'] = labels['y_pred'].apply(lambda x : corresp[x]) \n",
    "    \n",
    "    return labels['y_pred_transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_labels_transform = conf_mat_transform(labels, cls.labels_)\n",
    "conf_mat = metrics.confusion_matrix(labels, cls_labels_transform)\n",
    "print(conf_mat)\n",
    "print()\n",
    "print(metrics.classification_report(labels, cls_labels_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_mat, index = [label for label in list_labels],\n",
    "                  columns = [i for i in \"0123\"])\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La classe la moins bien pr√©dite est \"shine\" (CF exemple ci-dessus : confond la neige avec un nuage)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mission6_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
