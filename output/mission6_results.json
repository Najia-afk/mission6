{
  "data_analysis": {
    "value_analysis": "              key                   value  count  percentage  total_occurrences\n0            Type                  Analog    123       17.57                700\n1            Type                     Mug     72       10.29                700\n2            Type                  Ethnic     56        8.00                700\n3            Type  Wireless Without modem     27        3.86                700\n4            Type         Religious Idols     26        3.71                700\n5           Brand                Lapguard     11        2.08                529\n6           Brand              Lal Haveli     10        1.89                529\n7           Brand                 Raymond      8        1.51                529\n8           Brand                   Tenda      7        1.32                529\n9           Brand                Smartpro      7        1.32                529\n10  Sales Package                   1 Mug     48        9.74                493\n11  Sales Package    1 Showpiece Figurine     44        8.92                493\n12  Sales Package                   1 mug     22        4.46                493\n13  Sales Package                 Blanket     12        2.43                493\n14  Sales Package        1 Laptop Adapter     10        2.03                493\n15          Color              Multicolor     87       18.12                480\n16          Color                   Black     72       15.00                480\n17          Color                   White     42        8.75                480\n18          Color                    Blue     30        6.25                480\n19          Color                    Gold     28        5.83                480\n20      Ideal For                     Men     87       18.95                459\n21      Ideal For                   Women     74       16.12                459\n22      Ideal For              Men, Women     46       10.02                459\n23      Ideal For             Baby Girl's     45        9.80                459\n24      Ideal For           Men and Women     35        7.63                459",
    "category_distribution": 597,
    "dataset_size": 1000,
    "success": true
  },
  "text_processing": {
    "samples_processed": 1000,
    "tfidf_shape": [
      1000,
      1000
    ],
    "word2vec_shape": [
      100,
      100
    ],
    "bert_shape": [
      100,
      768
    ],
    "use_shape": [
      100,
      512
    ],
    "pca_variance": 0.85,
    "categories": 5,
    "embeddings": {
      "bert": "[[0.68786867 0.11514356 0.08256002 ... 0.37896588 0.35544379 0.33971785]\n [0.54756497 0.25775916 0.78079852 ... 0.30976953 0.8497487  0.20601562]\n [0.947321   0.9859213  0.25416361 ... 0.52490016 0.31523674 0.4114983 ]\n ...\n [0.17093915 0.07805478 0.63425192 ... 0.29858297 0.05102021 0.84033279]\n [0.16508363 0.89759298 0.07286311 ... 0.42318666 0.02458992 0.17447671]\n [0.43476009 0.2918944  0.99435946 ... 0.81241802 0.13907833 0.25436224]]"
    },
    "success": false,
    "error": "'explained_variance_ratio'"
  },
  "image_processing": {
    "images_processed": 15,
    "success_rate": 1.0,
    "basic_features_shape": [
      15,
      290
    ],
    "basic_silhouette": 0.1764122759688134,
    "feature_types": 290,
    "processed_images": [
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n ...\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.9647059  0.9882353  0.9882353 ]\n  [0.99215686 1.         1.        ]\n  [0.99215686 1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.99215686 0.99607843 0.99607843]\n  [0.99215686 1.         1.        ]\n  [0.99215686 1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.99215686 1.         1.        ]\n  [0.99215686 1.         1.        ]\n  [1.         1.         1.        ]]]",
      "[[[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n ...\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.76078431 0.87058824 0.97647059]\n  [0.76862745 0.87843137 0.98039216]\n  [0.77254902 0.86666667 0.94901961]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.77254902 0.87058824 0.97254902]\n  [0.78431373 0.87843137 0.98039216]\n  [0.90196078 0.96470588 1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.78431373 0.87843137 0.96470588]\n  [0.90196078 0.96470588 1.        ]\n  [0.94901961 1.         1.        ]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  ...\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]]\n\n [[0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  ...\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]]\n\n [[0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  ...\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]]\n\n ...\n\n [[0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  ...\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]]\n\n [[0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  ...\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]]\n\n [[0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  ...\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]\n  [0.9882353  0.99607843 0.99607843]]]",
      "[[[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n ...\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.45882353 0.46666667 0.50980395]\n  [0.7647059  0.7764706  0.7921569 ]\n  [0.99607843 0.99607843 0.99607843]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.4509804  0.46666667 0.50980395]\n  [0.45882353 0.46666667 0.50980395]\n  [0.7647059  0.7764706  0.7921569 ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.4509804  0.45882353 0.50980395]\n  [0.4509804  0.45882353 0.50980395]\n  [0.58431375 0.59607846 0.6313726 ]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  ...\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]]\n\n [[0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  ...\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]]\n\n [[0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  ...\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]]\n\n ...\n\n [[0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  ...\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]]\n\n [[0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  ...\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]]\n\n [[0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  ...\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]\n  [0.9882353 0.9882353 0.9882353]]]",
      "[[[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.98039216 1.         0.99607843]\n  [0.9764706  0.99607843 0.99607843]\n  [0.9764706  0.99215686 0.99607843]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.98039216 0.99607843 0.99607843]\n  [0.98039216 0.99607843 0.99607843]\n  [0.98039216 1.         0.99607843]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [0.98039216 0.99607843 0.99215686]\n  [0.9843137  0.99607843 0.98039216]\n  [0.9843137  1.         0.98039216]]\n\n ...\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]\n\n [[1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  ...\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]\n  [1.         1.         1.        ]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]",
      "[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n ...\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]\n  ...\n  [1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]"
    ],
    "basic_features": "<ndarray shape=(15, 290)>",
    "success": true
  },
  "deep_learning": {
    "deep_features": "<ndarray shape=(15, 25088)>",
    "deep_features_pca": "<ndarray shape=(15, 14)>",
    "deep_features_shape": [
      15,
      25088
    ],
    "pca_shape": [
      15,
      14
    ],
    "clustering_results": {
      "n_clusters": "2",
      "cluster_labels": "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]",
      "silhouette_score": "0.07779018",
      "kmeans_model": "KMeans(n_clusters=2, n_init=10, random_state=42)",
      "cluster_centers": "[[-8.9856319e+00 -2.1281328e+00 -1.0081116e+00 -2.8379886e+00\n  -1.2554798e+00  1.6256048e-01 -1.6573926e+00 -6.5242767e-01\n  -1.6240005e-01 -2.7855968e-01  4.1571888e-01  9.7583510e-02\n   2.0583807e-02  1.9571106e-01]\n [ 1.2579818e+02  2.9794804e+01  1.4111931e+01  3.9732876e+01\n   1.7576180e+01 -2.2754517e+00  2.3203663e+01  9.1323566e+00\n   2.2744606e+00  3.8996673e+00 -5.8198862e+00 -1.3661315e+00\n  -2.8800574e-01 -2.7400718e+00]]",
      "silhouette_scores": [
        "0.07779018",
        "0.07567036",
        "0.031688455",
        "0.038157653",
        "0.030386541",
        "0.028424522",
        "0.041031055",
        "-0.0012201247",
        "0.0044285967"
      ],
      "inertias": [
        201357.890625,
        180642.4375,
        165437.015625,
        144714.125,
        126937.203125,
        112446.7890625,
        91309.2890625,
        79419.8359375,
        61893.90625
      ],
      "cluster_range": [
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10
      ]
    },
    "silhouette_score": "0.07779018",
    "processing_times": [
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276,
      0.05155646006266276
    ],
    "feature_summary": {
      "feature_shape": [
        15,
        25088
      ],
      "total_features": 25088,
      "samples_processed": 15,
      "model_layer": "block5_pool",
      "processing_times": {
        "mean": 0.051556460062662776,
        "std": 1.3877787807814457e-17,
        "min": 0.05155646006266276,
        "max": 0.05155646006266276
      },
      "feature_statistics": {
        "mean": "1.8887535",
        "std": "9.239122",
        "min": "0.0",
        "max": "383.7567"
      }
    },
    "success": true
  },
  "multimodal_fusion": {
    "strategies_tested": 4,
    "fusion_results": {
      "Text_Deep": {
        "features_shape": [
          15,
          782
        ],
        "pca_shape": [
          15,
          14
        ],
        "silhouette_score": 0.009613243956070784,
        "cluster_labels": "[2 2 0 2 2 2 2 1 0 1 1 2 0 2 1]",
        "tsne_coords": "[[ 81.93161   34.864403]\n [ 25.052841 -48.972515]\n [-35.408478 164.23712 ]\n [107.736595  46.480392]\n [  6.347198 -47.837673]\n [ 57.798923 -40.719448]\n [ 74.75994  -18.969204]\n [ -8.711568  67.31946 ]\n [-28.216043 134.50127 ]\n [-21.147955  51.202522]\n [-23.362663 115.28174 ]\n [ 65.87773   24.672398]\n [-40.164318 185.73581 ]\n [ 41.132984  36.153793]\n [-33.75963   30.62469 ]]",
        "variance_explained": 0.9999999999999998,
        "n_components": 14,
        "pca_model": "PCA(n_components=14)",
        "kmeans_model": "KMeans(n_clusters=3, n_init=10, random_state=42)"
      },
      "Text_Basic": {
        "features_shape": [
          15,
          1058
        ],
        "pca_shape": [
          15,
          14
        ],
        "silhouette_score": 0.04512387763344457,
        "cluster_labels": "[1 2 0 2 2 2 0 2 1 1 0 1 0 1 1]",
        "tsne_coords": "[[  18.430979   -69.320404 ]\n [ 185.58559     33.71833  ]\n [-134.25372     61.21403  ]\n [  23.222286    97.82502  ]\n [  72.73675     67.09068  ]\n [ 105.60014     84.57702  ]\n [ -48.12787     15.369116 ]\n [ 200.16524     54.96776  ]\n [  54.189693   -40.77524  ]\n [  26.73334    -36.514454 ]\n [ -84.92968     20.122217 ]\n [  -2.0590386   48.180706 ]\n [-101.7946      63.801064 ]\n [ -29.179405    79.65599  ]\n [  26.036018    40.579285 ]]",
        "variance_explained": 1.0000000000000002,
        "n_components": 14,
        "pca_model": "PCA(n_components=14)",
        "kmeans_model": "KMeans(n_clusters=3, n_init=10, random_state=42)"
      },
      "Text_Deep_Basic": {
        "features_shape": [
          15,
          1072
        ],
        "pca_shape": [
          15,
          14
        ],
        "silhouette_score": 0.04453281682847337,
        "cluster_labels": "[1 2 0 2 2 2 0 2 1 1 0 1 0 1 1]",
        "tsne_coords": "[[ 39.37694   -42.32026  ]\n [ 69.105675   54.988937 ]\n [-45.347862   42.5483   ]\n [ 35.29901    12.171342 ]\n [ 16.042053   44.61095  ]\n [ 15.293279   62.511456 ]\n [-28.985907    1.7347924]\n [ 69.82802    67.27683  ]\n [ 17.03464   -43.074127 ]\n [ 26.151043  -33.496624 ]\n [-22.990088   18.401188 ]\n [  3.7004306  12.557424 ]\n [-30.332289   38.62928  ]\n [  5.280298   -8.141454 ]\n [ 13.939142   21.039982 ]]",
        "variance_explained": 0.9999999999999999,
        "n_components": 14,
        "pca_model": "PCA(n_components=14)",
        "kmeans_model": "KMeans(n_clusters=3, n_init=10, random_state=42)"
      },
      "Weighted_Text_Deep": {
        "features_shape": [
          15,
          782
        ],
        "pca_shape": [
          15,
          14
        ],
        "silhouette_score": 0.008896901808333958,
        "cluster_labels": "[2 2 0 2 2 2 2 1 0 1 1 2 0 2 1]",
        "tsne_coords": "[[  34.08099      5.6404223]\n [ -32.463264    65.388336 ]\n [  49.46636   -119.27277  ]\n [  59.067513    10.3267   ]\n [ -47.850075    58.95298  ]\n [  -2.5355008   67.889015 ]\n [  17.899464    54.11245  ]\n [  -9.284347   -53.24187  ]\n [  26.139818  -104.41017  ]\n [ -27.101336   -50.081005 ]\n [  12.844159   -92.67133  ]\n [  19.098753    13.784732 ]\n [  67.61844   -126.84768  ]\n [  -2.5427485    2.8792894]\n [ -47.667805   -43.91706  ]]",
        "variance_explained": 0.9999999999999999,
        "n_components": 14,
        "pca_model": "PCA(n_components=14)",
        "kmeans_model": "KMeans(n_clusters=3, n_init=10, random_state=42)"
      }
    },
    "ensemble_results": {
      "Majority_Text_Deep": {
        "silhouette_score": "0.008245076",
        "n_clusters": 2,
        "predictions": "[1 0 1 1 0 0 0 0 1 1 0 0 0 1 1]"
      },
      "Weighted_Text_Deep": {
        "silhouette_score": "-0.13195959",
        "n_clusters": 3,
        "predictions": "[2 0 1 1 0 0 0 0 1 1 0 0 0 1 1]"
      },
      "Majority_All": {
        "silhouette_score": "-0.08294408",
        "n_clusters": 3,
        "predictions": "[1 0 2 1 0 0 0 1 1 1 0 1 0 1 1]"
      },
      "Weighted_All": {
        "silhouette_score": "-0.13195959",
        "n_clusters": 3,
        "predictions": "[2 0 1 1 0 0 0 0 1 1 0 0 0 1 1]"
      }
    },
    "best_approaches": {
      "Feature_Text_Basic": 0.04512387763344457,
      "Feature_Text_Deep_Basic": 0.04453281682847337,
      "Feature_Text_Deep": 0.009613243956070784,
      "Feature_Weighted_Text_Deep": 0.008896901808333958,
      "Ensemble_Majority_Text_Deep": "0.008245076",
      "Ensemble_Majority_All": "-0.08294408",
      "Ensemble_Weighted_Text_Deep": "-0.13195959",
      "Ensemble_Weighted_All": "-0.13195959"
    },
    "best_approach": "Feature_Text_Basic",
    "best_score": 0.04512387763344457,
    "aligned_samples": 15,
    "improvement": 25.0,
    "success": true
  },
  "feasibility_assessment": {
    "final_metrics": {},
    "assessment_scores": {
      "Overall": 0.5
    },
    "overall_feasibility": 0.5,
    "recommendations": [],
    "roadmap": [],
    "final_report": {
      "executive_summary": {
        "overall_feasibility": 0.5,
        "production_readiness": "Medium",
        "recommendation": "Proceed with caution"
      }
    },
    "production_readiness": "Medium",
    "recommendation": "Proceed with caution",
    "success": false,
    "error": "'strategies_tested'"
  }
}