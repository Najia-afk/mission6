{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalAveragePooling1D, Flatten, Dense, Dropout \n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# os.environ[\"TF_KERAS\"]='1'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n",
      "1050\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image_path",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7c189375-5e1e-412f-8425-cd311aa33549",
       "rows": [
        [
         "0",
         "./dataset/Flipkart/Images/aa68675f50a0551b8dadb954017a50a1.jpg",
         "no_name ",
         "0"
        ],
        [
         "1",
         "./dataset/Flipkart/Images/037c2402fee39fbc80433935711d1383.jpg",
         "no_name ",
         "0"
        ],
        [
         "2",
         "./dataset/Flipkart/Images/42643c1c9403f67921a18654bcf45ead.jpg",
         "no_name ",
         "0"
        ],
        [
         "3",
         "./dataset/Flipkart/Images/53f4bc7d7321f5c41de6b86e41f13e80.jpg",
         "no_name ",
         "0"
        ],
        [
         "4",
         "./dataset/Flipkart/Images/b144a363c107c7bdd91f32d6e28ba6f2.jpg",
         "no_name ",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/Flipkart/Images/aa68675f50a0551b8dad...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/Flipkart/Images/037c2402fee39fbc8043...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/Flipkart/Images/42643c1c9403f67921a1...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/Flipkart/Images/53f4bc7d7321f5c41de6...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/Flipkart/Images/b144a363c107c7bdd91f...</td>\n",
       "      <td>no_name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path label_name  label\n",
       "0  ./dataset/Flipkart/Images/aa68675f50a0551b8dad...   no_name       0\n",
       "1  ./dataset/Flipkart/Images/037c2402fee39fbc8043...   no_name       0\n",
       "2  ./dataset/Flipkart/Images/42643c1c9403f67921a1...   no_name       0\n",
       "3  ./dataset/Flipkart/Images/53f4bc7d7321f5c41de6...   no_name       0\n",
       "4  ./dataset/Flipkart/Images/b144a363c107c7bdd91f...   no_name       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "path = \"./dataset/Flipkart/Images/\"\n",
    "path_test = \"./dataset/Flipkart/Images/\"\n",
    "\n",
    "\n",
    "list_labels = [\"cloudy\", \"rain\", \"shine\", \"sunrise\"]\n",
    "label_no_name = \"no_name \"\n",
    "\n",
    "def photo_class(photo) :\n",
    "    for label in list_labels :\n",
    "        if label in photo[24:] : \n",
    "            return label\n",
    "    return label_no_name\n",
    "    \n",
    "data_path = glob(path+'*.jp*')\n",
    "data_test_path = glob(path_test+'*.jp*')\n",
    "\n",
    "def data_fct(path) :\n",
    "    list_photos = [file for file in path]\n",
    "    print(len(list_photos))\n",
    "    data = pd.DataFrame()\n",
    "    data[\"image_path\"] = list_photos\n",
    "    data[\"label_name\"] = data[\"image_path\"].apply(lambda x : photo_class(x))\n",
    "    return data\n",
    "\n",
    "data = data_fct(data_path)\n",
    "data_test = data_fct(data_test_path)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data[\"label_name\"])\n",
    "data[\"label\"] = le.transform(data[\"label_name\"])\n",
    "data_test[\"label\"] = le.transform(data_test[\"label_name\"])\n",
    "# data.head(5)\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "image_path",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label_name",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b356cf51-3731-4d92-93ea-838e1215a751",
       "rows": [],
       "shape": {
        "columns": 2,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image_path, label_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloudy\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m     16\u001b[39m     plt.subplot(\u001b[32m130\u001b[39m + \u001b[32m1\u001b[39m + i)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     filename = \u001b[43mlist_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     18\u001b[39m     image = imread(filename)\n\u001b[32m     19\u001b[39m     plt.imshow(image)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.image import imread\n",
    "\n",
    "def list_fct(name) :\n",
    "    list_image_name = [data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==name]\n",
    "    return list_image_name\n",
    "\n",
    "list_cloudy=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"cloudy\"]\n",
    "list_rain=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"rain\"]\n",
    "list_shine=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"shine\"]\n",
    "list_sunrise=[data[\"image_path\"][i] for i in range(len(data)) if data[\"label_name\"][i]==\"sunrise\"]\n",
    "\n",
    "for name in list_labels :\n",
    "    print(name)\n",
    "    # print(\"-------\")\n",
    "    for i in range(3):\n",
    "        plt.subplot(130 + 1 + i)\n",
    "        filename = list_fct(name)[i+10]\n",
    "        image = imread(filename)\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 : étude de faisabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle pré-entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG16()\n",
    "model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des features des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T13:11:24.767685Z",
     "start_time": "2020-12-31T13:09:49.843465Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_features = []\n",
    "i=0 \n",
    "for image_file in data[\"image_path\"] :\n",
    "    if i%100 == 0 : print(i)\n",
    "    i +=1\n",
    "    image = load_img(image_file, target_size=(224, 224))\n",
    "    image = img_to_array(image) \n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    images_features.append(model.predict(image, verbose=0)[0]) # predict from pretrained model\n",
    "\n",
    "images_features = np.asarray(images_features)\n",
    "images_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction dimension et analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction de dimension PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition\n",
    "\n",
    "print(images_features.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "feat_pca= pca.fit_transform(images_features)\n",
    "print(feat_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction de dimension T-SNE et affichage des images selon vraies classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition\n",
    "import time\n",
    "\n",
    "temps1 = time.time()\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000, init='random', random_state=6)\n",
    "X_tsne = tsne.fit_transform(feat_pca)\n",
    "\n",
    "duration1=time.time()-temps1\n",
    "print(\"temps de T-SNE : \", \"%15.2f\" % duration1, \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = pd.DataFrame(X_tsne, columns=['tsne1', 'tsne2'])\n",
    "df_tsne[\"class\"] = data[\"label_name\"]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"class\",\n",
    "    palette=sns.color_palette('tab10', n_colors=4), s=50, alpha=0.6,\n",
    "    data=df_tsne,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE selon les vraies classes', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'analyse graphique montre visuellement qu'il est réalisable de séparer automatiquement les images selon leurs vraies classes\n",
    "* Ceci suffit à démontrer la faisabilité de réaliser ultérieurement une classification supervisée pour déterminer automatiquement les classes des images\n",
    "* Cette étape 1 est très rapide à mettre en oeuvre. Une conclusion négative sur la faisabilité aurait éviter de réaliser des traitements beaucoup plus lourd de classification supervisée\n",
    "* Cette démarche en 2 étapes (1. Faisabilité, 2. Classification supervisée si étape 1 OK) s'inscrit dans une démarche agile de tout projet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de clusters à partir du T-SNE et affichage des images selon clusters\n",
    "* Attention : ici, il ne s'agit pas de faire une classification non supervisée, mais simplement, par une mesure de l'ARI, de conforter l'analyse graphique précédente qui démontre la faisabilité de réaliser ultérieurement une classification supervisée. Cette mesure de l'ARI nécessite de créer des clusters théoriques via KMeans\n",
    "* Il s'agit donc de réaliser une mesure de ce que nous voyons graphiquement, donc à partir des données en sortie du t-sne\n",
    "* Pour réaliser une classification non supervisée, il aurait fallu repartir des données avant t-sne\n",
    "* Dans la démarche en 2 étapes, il n'est pas utile de réaliser une classification non supervisée, une classification supervisée est bien plus performante. Même le calcul de l'ARI n'est pas indispensable, nous pourrions passer directement du graphique t-sne précédent à l'étape 2 de classification supervisée\n",
    "* Il n'est donc pas utile de passer du temps à optimiser l'ARI, un ordre de grandeur suffit pour conforter le 1er graphique t-sne. D'ailleurs la meilleure solution de feature engineering ne génère pas toujours le meilleur ARI. L'analyse graphique t-sne est bien plus riche d'enseignement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, metrics\n",
    "\n",
    "cls = cluster.KMeans(n_clusters=4, n_init=100)\n",
    "cls.fit(X_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tsne[\"cluster\"] = cls.labels_\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette('tab10', n_colors=4), s=50, alpha=0.6,\n",
    "    data=df_tsne,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = data[\"label\"]\n",
    "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse d'image \"shine\" affectées au cluster 3 \"cloudy\"\n",
    "\n",
    "list_shine_0 = [i for i in range(len(data[\"image_path\"])) \\\n",
    "                if (data.iloc[i]['label_name']=='shine') and (df_tsne.iloc[i]['cluster']==3)]\n",
    "list_shine_0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage image \"shine\" considérée comme \"cloudy\"\n",
    "id = 220\n",
    "print(df_tsne.iloc[id])\n",
    "fig = plt.figure(figsize = (8, 5))\n",
    "# plt.subplot(130 + 1 + i)\n",
    "filename = data[\"image_path\"][id]\n",
    "image = imread(filename)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyse : le modèle pré-entraîné confond \"cloud\" avec de la neige ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse par classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(labels, cls.labels_)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_transform(y_true,y_pred) :\n",
    "    conf_mat = metrics.confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    corresp = np.argmax(conf_mat, axis=0)\n",
    "    print (\"Correspondance des clusters : \", corresp)\n",
    "    # y_pred_transform = np.apply_along_axis(correspond_fct, 1, y_pred)\n",
    "    labels = pd.Series(y_true, name=\"y_true\").to_frame()\n",
    "    labels['y_pred'] = y_pred\n",
    "    labels['y_pred_transform'] = labels['y_pred'].apply(lambda x : corresp[x]) \n",
    "    \n",
    "    return labels['y_pred_transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_labels_transform = conf_mat_transform(labels, cls.labels_)\n",
    "conf_mat = metrics.confusion_matrix(labels, cls_labels_transform)\n",
    "print(conf_mat)\n",
    "print()\n",
    "print(metrics.classification_report(labels, cls_labels_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_mat, index = [label for label in list_labels],\n",
    "                  columns = [i for i in \"0123\"])\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La classe la moins bien prédite est \"shine\" (CF exemple ci-dessus : confond la neige avec un nuage)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mission6_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
